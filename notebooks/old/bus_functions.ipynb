{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"/home/canyon/Bus-Weather-Impacts\")\n",
    "from src.utils import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.float_format', '{:.02f}'.format)\n",
    "from geopy.distance import geodesic\n",
    "from shapely.geometry import Point\n",
    "calculated_pair_path = \"data/node_pairs.parquet\"\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(row, graph):\n",
    "    try:\n",
    "        return nx.shortest_path_length(graph, row['prev_osmid'], row['osmid'], weight='travel_time')\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None\n",
    "    \n",
    "def compute_path(row, graph):\n",
    "    try:\n",
    "        return nx.shortest_path(graph, row['prev_osmid'], row['osmid'], weight='travel_time')\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None\n",
    "    \n",
    "def compute_euclid_dists(node_pairs, nodes_points):\n",
    "    nodes_points = nodes_points.to_crs(2263)\n",
    "    nodes_points[\"x\"] = nodes_points[\"geometry\"].x\n",
    "    nodes_points[\"y\"] = nodes_points[\"geometry\"].y\n",
    "\n",
    "    node_pairs = node_pairs.merge(nodes_points, left_on = \"osmid\", right_on = \"osmid\", how = \"left\").merge(nodes_points, right_on = \"osmid\", left_on = \"prev_osmid\", how = \"left\", suffixes = [\"curr\", \"prev\"])\n",
    "    node_pairs[\"x_diff_sq\"] = (node_pairs[\"xcurr\"] - node_pairs[\"xprev\"])**2\n",
    "    node_pairs[\"y_diff_sq\"] = (node_pairs[\"ycurr\"] - node_pairs[\"yprev\"])**2\n",
    "\n",
    "    return (node_pairs[\"x_diff_sq\"] + node_pairs[\"y_diff_sq\"]) ** (1/2) / 3.28\n",
    "\n",
    "def compute_euclid_dists(node_pairs, nodes_points):\n",
    "    nodes_points = nodes_points.to_crs(2263)\n",
    "    nodes_points[\"x\"] = nodes_points[\"geometry\"].x\n",
    "    nodes_points[\"y\"] = nodes_points[\"geometry\"].y\n",
    "\n",
    "    node_pairs = node_pairs.merge(nodes_points, left_on = \"osmid\", right_on = \"osmid\", how = \"left\").merge(nodes_points, right_on = \"osmid\", left_on = \"prev_osmid\", how = \"left\", suffixes = [\"curr\", \"prev\"])\n",
    "    node_pairs[\"x_diff_sq\"] = (node_pairs[\"xcurr\"] - node_pairs[\"xprev\"])**2\n",
    "    node_pairs[\"y_diff_sq\"] = (node_pairs[\"ycurr\"] - node_pairs[\"yprev\"])**2\n",
    "\n",
    "    return (node_pairs[\"x_diff_sq\"] + node_pairs[\"y_diff_sq\"]) ** (1/2) / 3.28\n",
    "\n",
    "def precalculate_node_pair_distances(node_pair_df, calculated_pair_path, G, nodes):\n",
    "    try:\n",
    "        calculated_pairs = pd.read_parquet(calculated_pair_path)\n",
    "    except:\n",
    "        print(\"No pre-calulated pairs found\")\n",
    "        calculated_pairs = pd.DataFrame(columns = [\"osmid\", \"prev_osmid\", \"distance_osm\", \"distance_euclid\", \"shortest_path\", \"dist_ratio\"])\n",
    "\n",
    "    node_pair_df = node_pair_df.drop_duplicates().dropna()\n",
    "    node_pair_df = node_pair_df.merge(calculated_pairs, on=[\"osmid\", \"prev_osmid\"], how=\"outer\")\n",
    "    pairs_to_calc = node_pair_df.query(\"distance_euclid.isna()\").reset_index(drop = True)\n",
    "    print(pairs_to_calc.shape)\n",
    "    \n",
    "    if pairs_to_calc.shape[0] > 0:\n",
    "        pairs_to_calc[\"distance_osm\"] = pairs_to_calc.apply(compute_distance, graph=G, axis=1)\n",
    "        pairs_to_calc[\"distance_euclid\"] = compute_euclid_dists(pairs_to_calc, nodes) \n",
    "        pairs_to_calc[\"shortest_path\"] = pairs_to_calc.apply(compute_path, graph=G, axis=1)\n",
    "\n",
    "        pairs_to_calc[\"dist_ratio\"] = pairs_to_calc[\"distance_euclid\"] / pairs_to_calc[\"distance_osm\"]\n",
    "\n",
    "        calculated_pairs = pd.concat([calculated_pairs, pairs_to_calc])\n",
    "        calculated_pairs.to_parquet(calculated_pair_path)\n",
    "        print(f\"Wrote calculated pairs to {calculated_pair_path}\")\n",
    "    else:\n",
    "        print(\"No new pairs to calculate\")\n",
    "\n",
    "def prep_buses_nodes(buses_with_nodes, max_distance_to_node):\n",
    "\n",
    "    buses_with_nodes = buses_with_nodes.sort_values([\"trip_id\", \"timestamp\"]).drop_duplicates(subset = [\"trip_id\", \"osmid\"],  keep = \"first\").to_crs(2263)\n",
    "    buses_with_nodes = buses_with_nodes[[\"route_short\", \"timestamp\", \"trip_id\", \"next_stop_id\", \"osmid\", \"vehicle_id\", \"distance_to_node\", \"geometry\"]]\n",
    "    buses_with_nodes[\"prev_stop_id\"] = buses_with_nodes[\"next_stop_id\"].shift(1)\n",
    "    buses_with_nodes[\"prev_osmid\"] = buses_with_nodes.groupby(\"trip_id\")[\"osmid\"].shift(1)\n",
    "    buses_with_nodes[\"next_osmid\"] = buses_with_nodes.groupby(\"trip_id\")[\"osmid\"].shift(-1)\n",
    "\n",
    "    buses_with_nodes[\"prev_osmid\"] = buses_with_nodes[\"prev_osmid\"].astype(float)\n",
    "    buses_with_nodes[\"osmid\"] = buses_with_nodes[\"osmid\"].astype(float)\n",
    "\n",
    "    buses_with_nodes = buses_with_nodes.query(\"distance_to_node < @max_distance_to_node\")\n",
    "\n",
    "    return buses_with_nodes\n",
    "\n",
    "\n",
    "def tag_feed_with_nodes(buses, tree, nodes, types_to_include = [np.NaN, \"traffic_signals\", \"stop\"]):\n",
    "    nodes = nodes[nodes[\"highway\"].isin(types_to_include)]\n",
    "    nearest_nodes = tree.query(np.array(buses[['lat', 'lon']]), k=1, return_distance=False)\n",
    "    buses['nearest_node'] = nearest_nodes.flatten()\n",
    "\n",
    "    # Map node IDs to OSM IDs\n",
    "    buses['nearest_osm_id'] = buses['nearest_node'].map(nodes['osmid'])\n",
    "    buses = buses.merge(nodes, left_on = \"nearest_osm_id\", right_on = \"osmid\")\n",
    "    buses = gpd.GeoDataFrame(buses, geometry='geometry')\n",
    "\n",
    "    return buses\n",
    "\n",
    "def get_node_data(place = \"New York City, New York, USA\"):\n",
    "    G = ox.graph_from_place(place, network_type='drive')\n",
    "\n",
    "    G = ox.add_edge_speeds(G)\n",
    "    G = ox.add_edge_travel_times(G)\n",
    "    # Convert graph nodes to a DataFrame for KDTree\n",
    "    nodes = ox.graph_to_gdfs(G, edges=False).reset_index()\n",
    "    tree = KDTree(nodes[['y', 'x']], metric='euclidean')\n",
    "\n",
    "    return tree, nodes, G\n",
    "\n",
    "def prep_coords(df, lat_col, lon_col):\n",
    "\n",
    "    df['geometry'] = df.apply(lambda row: Point(row[lon_col], row[lat_col]), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry').set_crs(4326)\n",
    "\n",
    "    gdf[\"planar_x\"] = gdf.to_crs(2263).geometry.x\n",
    "    gdf[\"planar_y\"] = gdf.to_crs(2263).geometry.y\n",
    "    \n",
    "    gdf = gdf.drop('geometry', axis = 1)\n",
    "    return gdf\n",
    "\n",
    "def calculate_distance_to_node(buses_with_nodes):\n",
    "\n",
    "    out = ((buses_with_nodes.to_crs(2263).geometry.x - buses_with_nodes[\"planar_x\"])**2 + (buses_with_nodes.to_crs(2263).geometry.y - buses_with_nodes[\"planar_y\"])**2)**(1/2)\n",
    "\n",
    "    return out\n",
    "\n",
    "def calculate_speeds(prepped_trips, calculated_pair_path = \"data/node_pairs.parquet\", minimum_time_diff = 45):\n",
    "    \n",
    "    node_pair_dists = pd.read_parquet(calculated_pair_path)\n",
    "\n",
    "    prepped_trips[\"time_diff_seconds\"] = prepped_trips.groupby(\"trip_id\")[\"timestamp\"].diff().dt.total_seconds()\n",
    "    prepped_trips = prepped_trips.query(\"time_diff_seconds >= @minimum_time_diff\")\n",
    "\n",
    "    buses_with_distances = prepped_trips.merge(node_pair_dists)\n",
    "    buses_with_distances[\"speed_osm\"] = (buses_with_distances[\"distance_osm\"] / 1609) / (buses_with_distances[\"time_diff_seconds\"] / 3600)\n",
    "    buses_with_distances[\"speed_euclid\"] = (buses_with_distances[\"distance_euclid\"] / 1609) / (buses_with_distances[\"time_diff_seconds\"] / 3600)\n",
    "    \n",
    "    return buses_with_distances\n",
    "\n",
    "def explode_edges(row):\n",
    "    try:\n",
    "        nodes = row['shortest_path']\n",
    "        idxs = [int(row['index'])]*(len(nodes)-1)\n",
    "        osmids = nodes[1:len(nodes)]\n",
    "        prev_osmids = nodes[0:len(nodes)-1]        \n",
    "        d = pd.DataFrame(data={'idx':idxs,'from':prev_osmids,'to':osmids})\n",
    "    except:\n",
    "        d = pd.DataFrame(data={'idx':[pd.NA],'from':[pd.NA],'to':[pd.NA]})\n",
    "    \n",
    "    return d\n",
    "\n",
    "def get_bus_stops(path = \"/home/data/test/cities/C3562/stops.geojson\"):\n",
    "    bus_stops = gpd.read_file(path)\n",
    "    bus_agencies = [\"MTA NYCT\", \"MTABC\", \"MTA NYCT,MTABC\"]\n",
    "    bus_stops = bus_stops.query(\"agency_ids_serviced.isin(@bus_agencies)\")[[\"stop_id\", \"stop_name\", \"stop_lat\", \"stop_lon\", \"geometry\"]].rename({\"stop_lat\" : \"lat\", \"stop_lon\" : \"lon\"}, axis = 1)\n",
    "    bus_stops[\"stop_id\"] = [f\"MTA_{stop_id}\" for stop_id in bus_stops[\"stop_id\"]]\n",
    "    bus_stops = prep_coords(bus_stops, \"lat\", \"lon\")\n",
    "\n",
    "    return bus_stops\n",
    "\n",
    "def bus_stops_nodes(bus_stops, tree, nodes):\n",
    "    stops_with_nodes = tag_feed_with_nodes(bus_stops, tree, nodes)\n",
    "    stops_with_nodes[\"dist_to_node\"] = calculate_distance_to_node(stops_with_nodes)\n",
    "    stops_with_nodes = stops_with_nodes.query(\"dist_to_node < 200\")\n",
    "    stops_with_nodes = stops_with_nodes[[\"stop_id\", \"stop_name\", \"osmid\", \"dist_to_node\"]]\n",
    "\n",
    "    return stops_with_nodes\n",
    "\n",
    "def get_stop_pairs(bus_stops, raw_GTFS_path):\n",
    "    if raw_GTFS_path[:-2] == 'gz':\n",
    "        gtfs_rt = read_parquet_from_tar_gz(raw_GTFS_path)\n",
    "    else:\n",
    "        col_remappings = {\"vehicle.trip.trip_id\" : \"trip_id\", \"vehicle.timestamp\" : \"timestamp\", \"vehicle.position.latitude\" : \"lat\", \"vehicle.position.longitude\" : \"lon\", \"vehicle.trip.route_id\" : \"route_short\", \"vehicle.stop_id\" : \"next_stop_id\", \"vehicle.vehicle.id\": \"vehicle_id\"}\n",
    "        gtfs_rt = pd.read_parquet(raw_GTFS_path).rename(col_remappings, axis = 1)\n",
    "    gtfs_rt = gtfs_rt.merge(bus_stops, left_on=\"next_stop_id\", right_on = \"stop_id\", how = \"left\")\n",
    "    gtfs_rt = gtfs_rt[[\"trip_id\", \"route_short\", \"timestamp\", \"next_stop_id\"]].sort_values([\"trip_id\", \"timestamp\"]).drop_duplicates([\"trip_id\", \"next_stop_id\"]).dropna()\n",
    "    gtfs_rt[\"prev_stop_id\"] = gtfs_rt[\"next_stop_id\"].shift(1)\n",
    "    #gtfs_rt.loc[gtfs_rt[\"prev_stop_id\"].isna(), 'prev_stop_id'] = gtfs_rt[\"origin_id\"]\n",
    "\n",
    "    stop_pairs = gtfs_rt[[\"prev_stop_id\", \"next_stop_id\"]]\n",
    "\n",
    "    stop_pairs = stop_pairs.merge(bus_stops[[\"stop_id\", \"stop_name\", \"osmid\"]], left_on = \"prev_stop_id\", right_on = \"stop_id\").merge(bus_stops[[\"stop_id\", \"stop_name\", \"osmid\"]], left_on = \"next_stop_id\", right_on = \"stop_id\", suffixes = [\"_prev\", \"_next\"]).rename({\"osmid_next\" : \"osmid\", \"osmid_prev\" : \"prev_osmid\"}, axis = 1)\n",
    "    stop_pairs[\"osmid\"] = stop_pairs[\"osmid\"].astype(int)\n",
    "    stop_pairs[\"prev_osmid\"] = stop_pairs[\"prev_osmid\"].astype(int)\n",
    "\n",
    "    return stop_pairs.drop_duplicates()\n",
    "\n",
    "def get_pair_paths(stop_pairs, G, nodes, calculated_pair_path = \"data/node_pairs.parquet\"):\n",
    "    precalculate_node_pair_distances(stop_pairs[[\"osmid\", \"prev_osmid\"]], calculated_pair_path=calculated_pair_path, G = G, nodes = nodes)\n",
    "    node_pair_dists = pd.read_parquet(calculated_pair_path)\n",
    "    stop_pairs = stop_pairs[[\"osmid\", \"prev_osmid\", \"next_stop_id\", \"prev_stop_id\", \"stop_name_prev\", \"stop_name_next\"]].merge(node_pair_dists)\n",
    "    \n",
    "    return stop_pairs\n",
    "\n",
    "def full_process_stops(tree, nodes, G, GTFS_PATH, calculated_pair_path = \"data/node_pairs.parquet\", stops_path = \"/home/data/test/cities/C3562/stops.geojson\"):\n",
    "    bus_stops = get_bus_stops(stops_path)\n",
    "    bus_stops = bus_stops_nodes(bus_stops, tree, nodes)\n",
    "    stop_pairs = get_stop_pairs(bus_stops, GTFS_PATH)\n",
    "    stop_pairs = get_pair_paths(stop_pairs, G, nodes, calculated_pair_path)\n",
    "\n",
    "    return stop_pairs[[\"next_stop_id\", \"prev_stop_id\",  \"stop_name_prev\", \"stop_name_next\", \"shortest_path\"]].rename({\"shortest_path\" : \"shortest_path_stops\"}, axis = 1)\n",
    "\n",
    "def check_in_bus_path(row):\n",
    "    if isinstance(row[\"shortest_path_stops\"], (list, np.ndarray)):\n",
    "        return row[\"osmid\"] in row[\"shortest_path_stops\"]\n",
    "    return False\n",
    "\n",
    "def process_gtfs_rt_main(tree, nodes, G, gtfs_path, calculated_pair_path, out_path, stops_with_paths = None, max_distance_to_node = 100):\n",
    "\n",
    "    print(\"Preprocssing bus data\")\n",
    "    if gtfs_path[:-2] == 'gz':\n",
    "        buses = read_parquet_from_tar_gz(gtfs_path)\n",
    "    else:\n",
    "        col_remappings = {\"vehicle.trip.trip_id\" : \"trip_id\", \"vehicle.timestamp\" : \"timestamp\", \"vehicle.position.latitude\" : \"lat\", \"vehicle.position.longitude\" : \"lon\", \"vehicle.trip.route_id\" : \"route_short\", \"vehicle.stop_id\" : \"next_stop_id\", \"vehicle.vehicle.id\": \"vehicle_id\"}\n",
    "        buses = pd.read_parquet(gtfs_path).rename(col_remappings, axis = 1)\n",
    "    buses = prep_coords(buses, 'lat', 'lon')\n",
    "\n",
    "    print(\"Tagging bus locations with nodes\")\n",
    "    buses_with_nodes = tag_feed_with_nodes(buses, tree, nodes)\n",
    "    buses_with_nodes[\"distance_to_node\"] = calculate_distance_to_node(buses_with_nodes)\n",
    "\n",
    "\n",
    "    print(\"Calculating distance pairs\")\n",
    "    prepped_trips = prep_buses_nodes(buses_with_nodes, max_distance_to_node)\n",
    "\n",
    "    if stops_with_paths is not None:\n",
    "        print(prepped_trips.shape)\n",
    "        prepped_trips = prepped_trips.merge(stops_with_paths)\n",
    "        prepped_trips[\"in_bus_path\"] = prepped_trips.apply(check_in_bus_path, axis=1)\n",
    "        prepped_trips = prepped_trips.query(\"in_bus_path\")\n",
    "        print(prepped_trips.shape)\n",
    "\n",
    "\n",
    "    node_pair_df = prepped_trips[[\"osmid\", \"prev_osmid\"]]\n",
    "\n",
    "    precalculate_node_pair_distances(node_pair_df, calculated_pair_path, G, nodes)\n",
    "    buses_with_speeds = calculate_speeds(prepped_trips).reset_index()\n",
    "\n",
    "    print(\"Exploding edges\")\n",
    "    dfs = []\n",
    "    for i,row in buses_with_speeds.iterrows():\n",
    "        dfs.append(explode_edges(row))\n",
    "\n",
    "    segment_speeds = pd.concat(dfs)\n",
    "    bus_speed_segemented = buses_with_speeds.merge(segment_speeds, left_on = \"index\", right_on = \"idx\").drop([\"index\"], axis = 1)\n",
    "\n",
    "    print(\"Writing to parquet\")\n",
    "    bus_speed_segemented.to_parquet(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_parquet_from_tar_gz(\"https://urbantech-public.s3.amazonaws.com/DO-NOT-DELETE-BUSOBSERVATORY-PUBLIC-DATASET/one-system-day.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GTFS_PATH = \"https://urbantech-public.s3.amazonaws.com/DO-NOT-DELETE-BUSOBSERVATORY-PUBLIC-DATASET/one-system-day.tar.gz\"\n",
    "GTFS_PATH = \"/home/data/bus-weather/raw_bus_gtfs_rt_202230917_20230930.parquet\"\n",
    "CALCULATED_PAIR_PATH = \"data/node_pairs.parquet\"\n",
    "OUT_PATH = \"data/buses_with_segmented_storm.parquet\"\n",
    "STOPS_PATH = \"/home/data/test/cities/C3562/stops.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tree, nodes, G \u001b[38;5;241m=\u001b[39m \u001b[43mget_node_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 89\u001b[0m, in \u001b[0;36mget_node_data\u001b[0;34m(place)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_node_data\u001b[39m(place \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew York City, New York, USA\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m     G \u001b[38;5;241m=\u001b[39m \u001b[43mox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_from_place\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     G \u001b[38;5;241m=\u001b[39m ox\u001b[38;5;241m.\u001b[39madd_edge_speeds(G)\n\u001b[1;32m     92\u001b[0m     G \u001b[38;5;241m=\u001b[39m ox\u001b[38;5;241m.\u001b[39madd_edge_travel_times(G)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TOP-Sprint-lAvM2-mU/lib/python3.9/site-packages/osmnx/graph.py:394\u001b[0m, in \u001b[0;36mgraph_from_place\u001b[0;34m(query, network_type, simplify, retain_all, truncate_by_edge, which_result, buffer_dist, clean_periphery, custom_filter)\u001b[0m\n\u001b[1;32m    391\u001b[0m utils\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstructed place geometry polygon(s) to query API\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# create graph using this polygon(s) geometry\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_from_polygon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolygon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimplify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimplify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate_by_edge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate_by_edge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_periphery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_periphery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m utils\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph_from_place returned graph with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(G)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(G\u001b[38;5;241m.\u001b[39medges)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edges\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TOP-Sprint-lAvM2-mU/lib/python3.9/site-packages/osmnx/graph.py:501\u001b[0m, in \u001b[0;36mgraph_from_polygon\u001b[0;34m(polygon, network_type, simplify, retain_all, truncate_by_edge, clean_periphery, custom_filter)\u001b[0m\n\u001b[1;32m    495\u001b[0m G_buff \u001b[38;5;241m=\u001b[39m _create_graph(response_jsons, retain_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bidirectional\u001b[38;5;241m=\u001b[39mbidirectional)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# truncate buffered graph to the buffered polygon and retain_all for\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# now. needed because overpass returns entire ways that also include\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# nodes outside the poly if the way (that is, a way with a single OSM\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# ID) has a node inside the poly at some point.\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m G_buff \u001b[38;5;241m=\u001b[39m \u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncate_graph_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_buff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly_buff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate_by_edge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# simplify the graph topology\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m simplify:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TOP-Sprint-lAvM2-mU/lib/python3.9/site-packages/osmnx/truncate.py:194\u001b[0m, in \u001b[0;36mtruncate_graph_polygon\u001b[0;34m(G, polygon, retain_all, truncate_by_edge, quadrat_width, min_num)\u001b[0m\n\u001b[1;32m    190\u001b[0m     nodes_to_remove \u001b[38;5;241m=\u001b[39m nodes_outside_poly\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# now remove from the graph all those nodes that lie outside the polygon\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# make a copy to not mutate original graph object caller passed in\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m G\u001b[38;5;241m.\u001b[39mremove_nodes_from(nodes_to_remove)\n\u001b[1;32m    196\u001b[0m utils\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(nodes_to_remove)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes outside polygon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TOP-Sprint-lAvM2-mU/lib/python3.9/site-packages/networkx/classes/multigraph.py:1100\u001b[0m, in \u001b[0;36mMultiGraph.copy\u001b[0;34m(self, as_view)\u001b[0m\n\u001b[1;32m   1098\u001b[0m G\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m   1099\u001b[0m G\u001b[38;5;241m.\u001b[39madd_nodes_from((n, d\u001b[38;5;241m.\u001b[39mcopy()) \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m-> 1100\u001b[0m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_edges_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatadict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeydict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatadict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkeydict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TOP-Sprint-lAvM2-mU/lib/python3.9/site-packages/networkx/classes/multigraph.py:594\u001b[0m, in \u001b[0;36mMultiGraph.add_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add all the edges in ebunch_to_add.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m>>> assigned_keys = G.add_edges_from(list((5, n) for n in G.nodes))\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    593\u001b[0m keylist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 594\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m ebunch_to_add:\n\u001b[1;32m    595\u001b[0m     ne \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(e)\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ne \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/TOP-Sprint-lAvM2-mU/lib/python3.9/site-packages/networkx/classes/multigraph.py:1101\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1098\u001b[0m G\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m   1099\u001b[0m G\u001b[38;5;241m.\u001b[39madd_nodes_from((n, d\u001b[38;5;241m.\u001b[39mcopy()) \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m   1100\u001b[0m G\u001b[38;5;241m.\u001b[39madd_edges_from(\n\u001b[0;32m-> 1101\u001b[0m     (u, v, key, datadict\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u, nbrs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v, keydict \u001b[38;5;129;01min\u001b[39;00m nbrs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, datadict \u001b[38;5;129;01min\u001b[39;00m keydict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1105\u001b[0m )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tree, nodes, G = get_node_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_with_paths = full_process_stops(tree, nodes, G, GTFS_PATH, calculated_pair_path = CALCULATED_PAIR_PATH, stops_path = \"/home/data/test/cities/C3562/stops.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocssing bus data\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "process_gtfs_rt_main(tree, nodes, G, GTFS_PATH, CALCULATED_PAIR_PATH, OUT_PATH, stops_with_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_buses = gpd.read_parquet(OUT_PATH)\n",
    "old_buses = gpd.read_parquet(\"/home/canyon/Bus-Weather-Impacts/data/buses_with_segmented.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, .99]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_buses[[\"speed_osm\", \"speed_euclid\", \"dist_ratio\"]].describe(percentiles=quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_buses[[\"speed_osm\", \"speed_euclid\", \"dist_ratio\"]].describe(percentiles=quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_speed_segemented.query(\"speed_osm < 70\").query(\"`from` == 4209661118 & to == 4209661121.00\")['speed_osm'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_speeds.to_parquet(\"segments_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_trips[\"time_diff_seconds\"] = prepped_trips.groupby(\"trip_id\")[\"timestamp\"].diff().dt.total_seconds()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TOP-Sprint-lAvM2-mU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
